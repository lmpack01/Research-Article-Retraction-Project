{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Retraction Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retract = pd.read_csv('./total_retraction_data.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the \"Data Collection\" notebook, the querying script would have ideally run through the entire DOI column. However, I often had 404 errors or the script would stop abruptly with no error message. For this reason, I decided to break the DOI column into small sections to closely monitor the information and save the information I received frequently. Because of this, several CSV files were created, each labeled with what DOI index values were used when pulling the information. This information was then cleaned into one complete CSV file in a notebook that will not be provided. This CSV file is labeled as \"total_retraction_data.csv\" and was opened above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retract = retract.drop(columns=['Unnamed: 0', 'doi_check'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retract = retract.dropna(axis=0, subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retract['retraction_binary'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retract.to_csv('./no_null_text_retraction_data.csv')\n",
    "retract = pd.read_csv('./no_null_text_retraction_data.csv')\n",
    "retract = retract.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe was cleaned in several ways. Unnecessary columns were dropped. Any articles that had no text data were dropped. A new column named \"retraction_binary\" was created that was filled with the integer 1 to indicate that all of the articles in this dataframe were articles that had been retracted. Using .info method below, it is evident that the only remaining articles had full text. Once the data was cleaned, it was saved into a new CSV file for proofing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1553 entries, 0 to 1552\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 1553 non-null   int64  \n",
      " 1   doi                1553 non-null   object \n",
      " 2   language           1553 non-null   object \n",
      " 3   year               1315 non-null   float64\n",
      " 4   month              1315 non-null   float64\n",
      " 5   day                1315 non-null   float64\n",
      " 6   volume             1518 non-null   float64\n",
      " 7   issue              1043 non-null   float64\n",
      " 8   journal            1553 non-null   object \n",
      " 9   title              1553 non-null   object \n",
      " 10  page               1487 non-null   object \n",
      " 11  text               1553 non-null   object \n",
      " 12  abstract           1533 non-null   object \n",
      " 13  keywords           1553 non-null   object \n",
      " 14  publisher          1549 non-null   object \n",
      " 15  retraction_binary  1553 non-null   int64  \n",
      "dtypes: float64(5), int64(2), object(9)\n",
      "memory usage: 194.2+ KB\n"
     ]
    }
   ],
   "source": [
    "retract.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_keywords_list = []\n",
    "count = 0\n",
    "for i in retract['keywords']:\n",
    "    keywords_list = []\n",
    "    if i == []:\n",
    "        ls_keywords_list.append([])\n",
    "    else:\n",
    "        for j in i.split():\n",
    "            keywords_list.append(j.replace(\"'\",'').replace('[','').replace(',','').replace(']','').replace('(','').replace(')','').replace('\\\\n', '').replace('\\\\n','').lower())\n",
    "        if keywords_list == ['']:\n",
    "            ls_keywords_list.append([])\n",
    "        else:\n",
    "            ls_keywords_list.append(keywords_list)\n",
    "\n",
    "retract['unpacked_keywords'] = ls_keywords_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keywords list for each article was a string. In this format, this information is not useful. Because of this, the above script was used to \"unpack\" each keyword and place it into a true list. These lists were then placed into a new column, \"unpacked_keywords\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Lemmatizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "clean_text = []\n",
    "clean_text_lem = []\n",
    "\n",
    "for i in range(0, len(retract['text'])):\n",
    "    ls_words = []\n",
    "    ls_lem = []\n",
    "    for j in tokenizer.tokenize(retract['text'][i]):\n",
    "        try:\n",
    "            int(j)\n",
    "        except:\n",
    "            if len(j) < 45:\n",
    "                ls_words.append(j)\n",
    "                ls_lem.append(lemmatizer.lemmatize(j))\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "    clean_text.append(' '.join(ls_words))\n",
    "    clean_text_lem.append(' '.join(ls_lem))\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retract['clean_text'] = clean_text\n",
    "retract['clean_text_lem'] = clean_text_lem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text of each article as it was originally received from the query needed to be cleaned in several ways. There were several symbols and numerical values that needed to be removed. To remove these characters, the RegexpTokenizer was used. Additionally, several \"words\" were in fact URLs or strings of characters that were not intelligible (as they may have been artifacts from mathematical equations in the article). Thus, any string that was above 45 characters was ignored. Once these cleaning steps had been taken, the text was saved in two different ways: one method with no further formatting, and one method where a lemmatizer was used. The now two different text bodies were then combined back together using spaces and added to new columns in the dataframe. Text that had no further formatting was saved as \"clean_text\" while lemmatized text was saved as \"clean_text_lem\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning No Retraction Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting Indexing Error During PMC Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading all text CSV files from PMC querying\n",
    "text_one = pd.read_csv('./text__no_retraction__0_5545.csv')\n",
    "text_two = pd.read_csv('./text__no_retraction__5545_6166.csv')\n",
    "text_three = pd.read_csv('./text__no_retraction__6166_end.csv')\n",
    "\n",
    "#reading all abstract CSV files from PMC querying\n",
    "abstract_one = pd.read_csv('./abstract__no_retraction__0_5545.csv')\n",
    "abstract_two = pd.read_csv('./abstract__no_retraction__5545_6166.csv')\n",
    "abstract_three = pd.read_csv('./abstract__no_retraction__6166_end.csv')\n",
    "\n",
    "#reading all keyword CSV files from PMC querying\n",
    "keywords_one = pd.read_csv('./keywords__no_retraction__0_5545.csv')\n",
    "keywords_two = pd.read_csv('./keywords__no_retraction__5545_6166.csv')\n",
    "keywords_three = pd.read_csv('./keywords__no_retraction__6166_end.csv')\n",
    "\n",
    "#reading all publisher CSV files from PMC querying\n",
    "publisher_one = pd.read_csv('./publisher__no_retraction__0_5545.csv')\n",
    "publisher_two = pd.read_csv('./publisher__no_retraction__5545_6166.csv')\n",
    "publisher_three = pd.read_csv('./publisher__no_retraction__6166_end.csv')\n",
    "\n",
    "#reading all DOI CSV files from PMC querying\n",
    "doi_one = pd.read_csv('./doi__no_retraction__0_5545.csv')\n",
    "doi_two = pd.read_csv('./doi__no_retraction__5545_6166.csv')\n",
    "doi_three = pd.read_csv('./doi__no_retraction__6166_end.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the \"Data Collection\" notebook, the script would have ideally run through the entire DOI column. However, when using this function, I often had 404 errors or the script would stop abruptly with no error message. For this reason, I decided to break the DOI column into three different sections to closely monitor the information and save the information I received more frequently. Because of this, three different CSV files were created, each labeled with what DOI index values were used when pulling the information. These CSV files are opened in the above script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>5541</td>\n",
       "      <td>Winter air pollution in Ulaanbaatar, Mongolia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>5542</td>\n",
       "      <td>Chronic infection with hepatitis C virus (HCV)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>5543</td>\n",
       "      <td>California has one of the most highly engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>5544</td>\n",
       "      <td>Thiol-dependent cathepsins are found in all li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>5545</td>\n",
       "      <td>To estimate hepatitis C virus (HCV) viremic ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                                  0\n",
       "5541        5541  Winter air pollution in Ulaanbaatar, Mongolia ...\n",
       "5542        5542  Chronic infection with hepatitis C virus (HCV)...\n",
       "5543        5543  California has one of the most highly engineer...\n",
       "5544        5544  Thiol-dependent cathepsins are found in all li...\n",
       "5545        5545  To estimate hepatitis C virus (HCV) viremic ra..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_one.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>To estimate hepatitis C virus (HCV) viremic ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pollinators are crucial in almost all terrestr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The association of melanosis coli with the dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In most plant species, repetitive DNA constitu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>In the last decades, there has been a great in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  0\n",
       "0           0  To estimate hepatitis C virus (HCV) viremic ra...\n",
       "1           1  Pollinators are crucial in almost all terrestr...\n",
       "2           2  The association of melanosis coli with the dev...\n",
       "3           3  In most plant species, repetitive DNA constitu...\n",
       "4           4  In the last decades, there has been a great in..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_two.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>617</td>\n",
       "      <td>Bread wheat (Triticum aestivum L.) is one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>618</td>\n",
       "      <td>Metabolic syndrome (MetS), defined as a comple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>619</td>\n",
       "      <td>Competitive learning techniques are being succ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>620</td>\n",
       "      <td>In South East Africa, about 100,000 years ago ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>621</td>\n",
       "      <td>In the text of González-Fernández [1] can be f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                                  0\n",
       "617         617  Bread wheat (Triticum aestivum L.) is one of t...\n",
       "618         618  Metabolic syndrome (MetS), defined as a comple...\n",
       "619         619  Competitive learning techniques are being succ...\n",
       "620         620  In South East Africa, about 100,000 years ago ...\n",
       "621         621  In the text of González-Fernández [1] can be f..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_two.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>In the text of González-Fernández [1] can be f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Infantile spasms (IS) are the defining seizure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The arylamine N-acetyltransferases are a famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Several biomarkers have been proposed for ultr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Osteoporosis is a skeletal disease characteriz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  0\n",
       "0           0  In the text of González-Fernández [1] can be f...\n",
       "1           1  Infantile spasms (IS) are the defining seizure...\n",
       "2           2  The arylamine N-acetyltransferases are a famil...\n",
       "3           3  Several biomarkers have been proposed for ultr...\n",
       "4           4  Osteoporosis is a skeletal disease characteriz..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_three.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I realized I had duplicated two query calls when completing the PMC no retraction querying for the no retraction data. Because of this, I had to drop the appropriate rows from the CSV files for each piece of information determined while querying. The rows were dropped in the script below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicate entries from text dataframes\n",
    "text_one = text_one.drop(5545, axis=0)\n",
    "text_two = text_two.drop(621, axis=0)\n",
    "\n",
    "#dropping duplicate entries from abstract dataframes\n",
    "abstract_one = abstract_one.drop(5545, axis=0)\n",
    "abstract_two = abstract_two.drop(621, axis=0)\n",
    "\n",
    "#dropping duplicate entries from keywords dataframes\n",
    "keywords_one = keywords_one.drop(5545, axis=0)\n",
    "keywords_two = keywords_two.drop(621, axis=0)\n",
    "\n",
    "#dropping duplicate entries from publisher dataframes\n",
    "publisher_one = publisher_one.drop(5545, axis=0)\n",
    "publisher_two = publisher_two.drop(621, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all text dataframes\n",
    "text_total = pd.concat([text_one, text_two, text_three], axis =0)\n",
    "\n",
    "#combining all DOI dataframes\n",
    "doi_total = pd.concat([doi_one, doi_two, doi_three], axis =0)\n",
    "\n",
    "#combining all abstract dataframes\n",
    "abstract_total = pd.concat([abstract_one, abstract_two, abstract_three], axis =0)\n",
    "\n",
    "#combining all keyword dataframes\n",
    "keywords_total = pd.concat([keywords_one, keywords_two, keywords_three], axis =0)\n",
    "\n",
    "#combining all publisher dataframes\n",
    "publisher_total = pd.concat([publisher_one, publisher_two, publisher_three], axis =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each CSV file for each piece of information from the PMC query was concatenated together by row. Once the dataframe was created for each piece of information, the dataframe was then saved as a CSV file in the script below for proofing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving all concatenated dataframes for proofing\n",
    "text_total.to_csv('./plos_only_no_retraction_text.csv')\n",
    "doi_total.to_csv('./plos_only_no_retraction_doi.csv')\n",
    "abstract_total.to_csv('./plos_only_no_retraction_abstract.csv')\n",
    "keywords_total.to_csv('./plos_only_no_retraction_keywords.csv')\n",
    "publisher_total.to_csv('./plos_only_no_retraction_publisher.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rereading all concatenated dataframes to continue working\n",
    "text = pd.read_csv('./plos_only_no_retraction_text.csv')\n",
    "abstract = pd.read_csv('./plos_only_no_retraction_abstract.csv')\n",
    "keywords = pd.read_csv('./plos_only_no_retraction_keywords.csv')\n",
    "publisher = pd.read_csv('./plos_only_no_retraction_publisher.csv')\n",
    "doi = pd.read_csv('./plos_only_no_retraction_doi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Data from PMC Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling all text data for no retractions\n",
    "ls_text = []\n",
    "for i in text['0']:\n",
    "    ls_text.append(i)\n",
    "print(len(ls_text))\n",
    "\n",
    "#pulling all abstract data for no retractions\n",
    "ls_abstract = []\n",
    "for i in abstract['0']:\n",
    "    ls_abstract.append(i)\n",
    "print(len(ls_abstract))\n",
    "\n",
    "#pulling all keywords list data for no retractions\n",
    "ls_keywords = []\n",
    "for i in keywords['0']:\n",
    "    ls_keywords.append(i)\n",
    "print(len(ls_keywords))\n",
    "\n",
    "#pulling all publisher data for no retractions\n",
    "ls_publisher = []\n",
    "for i in publisher['0']:\n",
    "    ls_publisher.append(i)\n",
    "print(len(ls_publisher))\n",
    "\n",
    "#pulling all DOI data for no retractions\n",
    "ls_doi = []\n",
    "for i in doi['1']:\n",
    "    ls_doi.append(i)\n",
    "print(len(ls_doi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To place all of the information from the PMC no retraction query, the information from the newly formed CSV files was pulled and placed into a list for each information piece. The PubMed no retraction CSV file was then opened. All of the lists were concatenated with the PubMed no retraction dataframe to combine all of the no retraction inforamtion into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retract = pd.read_csv('./pubmed_data_second_no_retraction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retract = pd.concat([no_retract, pd.Series(ls_text), pd.Series(ls_abstract), pd.Series(ls_keywords), \n",
    "                        pd.Series(ls_publisher), pd.Series(ls_doi)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retract = no_retract.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retract = no_retract.rename(columns={'0':'id', '1':'doi', '2':'language', '3':'year', '4':'month', '5':'day', \n",
    "                      '6':'volume', '7':'issue', '8':'journal', '9':'title', '10':'page', \n",
    "                      0:'text', 1:'abstract', 2:'keywords', 3:'publisher', 4:'doi_check'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnecessary columns were dropped. For the columns that remain, the columns were renamed to the appropriate information based on the order in which the information was pulled during querying. The complete dataframe can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5540    10.1371/journal.pone.0186821\n",
       "5541    10.1371/journal.pone.0186834\n",
       "5542    10.1371/journal.pone.0186898\n",
       "5543    10.1371/journal.pone.0187181\n",
       "5544    10.1371/journal.pone.0186869\n",
       "5545    10.1371/journal.pone.0187177\n",
       "5546    10.1371/journal.pone.0187079\n",
       "5547    10.1371/journal.pone.0186668\n",
       "5548    10.1371/journal.pone.0187131\n",
       "5549    10.1371/journal.pone.0186957\n",
       "Name: doi, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_retract['doi'][5540:5550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5540    10.1371/journal.pone.0186821\n",
       "5541    10.1371/journal.pone.0186834\n",
       "5542    10.1371/journal.pone.0186898\n",
       "5543    10.1371/journal.pone.0187181\n",
       "5544    10.1371/journal.pone.0186869\n",
       "5545    10.1371/journal.pone.0187177\n",
       "5546    10.1371/journal.pone.0187079\n",
       "5547    10.1371/journal.pone.0186668\n",
       "5548    10.1371/journal.pone.0187131\n",
       "5549    10.1371/journal.pone.0186957\n",
       "Name: doi_check, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_retract['doi_check'][5540:5550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retract.to_csv('./plos_only_no_retraction_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DOI values were compared between the two different DOI columns to ensure that the concatenating between the different dataframes was completed accurately. Once it was determined that there were no errors in concatenating, the dataframe was saved as a new CSV file for proofing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retract = pd.read_csv('./plos_only_no_retraction_data.csv', index_col=False)\n",
    "no_retract = no_retract.drop(columns=['Unnamed: 0', 'doi_check'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "print(no_retract['abstract'].isnull().sum())\n",
    "print(no_retract['text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above script shows the number of null values in the \"abstract\" and \"text\" column. In the case that there is simply too much text in the full article to be used for NLP modeling, it may be possible to use the information in the abstract of each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retract = no_retract.dropna(axis=0, subset=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any articles that were missing text were dropped from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10.1371/journal.pone.0221236', '10.1371/journal.pone.0208797',\n",
       "       '10.1371/journal.pone.0145158', '10.1371/journal.pone.0184077',\n",
       "       '10.1371/journal.pone.0169155', '10.1371/journal.pone.0119129',\n",
       "       '10.1371/journal.pone.0175673', '10.1371/journal.pone.0226358',\n",
       "       '10.1371/journal.pone.0186309', '10.1371/journal.pone.0144882',\n",
       "       '10.1371/journal.pone.0217685', '10.1371/journal.pone.0168498',\n",
       "       '10.1371/journal.pone.0203429', '10.1371/journal.pone.0147806',\n",
       "       '10.1371/journal.pone.0210432', '10.1371/journal.pone.0201007',\n",
       "       '10.1371/journal.pone.0155713', '10.1371/journal.pone.0178620',\n",
       "       '10.1371/journal.pone.0135598', '10.1371/journal.pone.0178231',\n",
       "       '10.1371/journal.pone.0156508', '10.1371/journal.pone.0118722',\n",
       "       '10.1371/journal.pone.0179354', '10.1371/journal.pone.0221109',\n",
       "       '10.1371/journal.pone.0171148', '10.1371/journal.pone.0152195',\n",
       "       '10.1371/journal.pone.0131134', '10.1371/journal.pone.0216493',\n",
       "       '10.1371/journal.pone.0216062', '10.1371/journal.pone.0221297',\n",
       "       '10.1371/journal.pone.0136188', '10.1371/journal.pone.0214864',\n",
       "       '10.1371/journal.pone.0213110', '10.1371/journal.pone.0194065',\n",
       "       '10.1371/journal.pone.0224176', '10.1371/journal.pone.0168330',\n",
       "       '10.1371/journal.pone.0204061', '10.1371/journal.pone.0134110',\n",
       "       '10.1371/journal.pone.0176478', '10.1371/journal.pone.0182935',\n",
       "       '10.1371/journal.pone.0212236', '10.1371/journal.pone.0200779',\n",
       "       '10.1371/journal.pone.0174632', '10.1371/journal.pone.0195339',\n",
       "       '10.1371/journal.pone.0184493', '10.1371/journal.pone.0224195',\n",
       "       '10.1371/journal.pone.0152406', '10.1371/journal.pone.0156847',\n",
       "       '10.1371/journal.pone.0118853', '10.1371/journal.pone.0221362'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(no_retract['doi'], 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 DOIs of articles that were not retracted from PLOS ONE were pulled. These DOIs were used to manually check that the articles pulled during the query were in fact not retracted. While all of the articles proved to be not retracted, 5 of the articles had actually been corrected. The reasons for correction were as followed: author byline changes and fixing a citation, supporting figure appears incorrectly, authors spelled incorrectly, errors in figures, and affiliation listing error. Corrections are not the same as retractions, but may be something to look into in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retract['retraction_binary'] = 0\n",
    "print(no_retract['retraction_binary'].value_counts())\n",
    "no_retract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retract.to_csv('./no_null_text_plos_only_no_retraction_data.csv')\n",
    "no_retract = pd.read_csv('./no_null_text_plos_only_no_retraction_data.csv')\n",
    "no_retract = no_retract.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new column named \"retraction_binary\" was created that was filled with the integer 0 to indicate that all of the articles in this dataframe were articles that had not been retracted. Using .info method below, it is evident that the only remaining articles had full text. Once the data was cleaned, it was saved into a new CSV file for proofing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9214 entries, 0 to 9213\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id                 9214 non-null   int64 \n",
      " 1   doi                9214 non-null   object\n",
      " 2   language           9214 non-null   object\n",
      " 3   year               9214 non-null   int64 \n",
      " 4   month              9214 non-null   int64 \n",
      " 5   day                9214 non-null   int64 \n",
      " 6   volume             9214 non-null   int64 \n",
      " 7   issue              9214 non-null   int64 \n",
      " 8   journal            9214 non-null   object\n",
      " 9   title              9214 non-null   object\n",
      " 10  page               9214 non-null   object\n",
      " 11  text               9214 non-null   object\n",
      " 12  abstract           9119 non-null   object\n",
      " 13  keywords           9214 non-null   object\n",
      " 14  publisher          9214 non-null   object\n",
      " 15  retraction_binary  9214 non-null   int64 \n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "no_retract.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                                                                            9213\n",
       "['Socioeconomic inequality', 'Antenatal care', 'Decomposition', 'Nigeria']       1\n",
       "Name: keywords, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_retract['keywords'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I went to unpack the keywords list as I had done for the retraction data. However, after completing .value_counts method for the column, I realized that only one data point out of 9214 articles actually had a keywords list. I manually checked using the same 50 random DOI values to determine that none of the articles randomly chosen actually had a keywords list. Because of this, I did not bother to unpack the keywords list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Lemmatizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "clean_text = []\n",
    "clean_text_lem = []\n",
    "\n",
    "for i in range(0, len(no_retract['text'])):\n",
    "    ls_words = []\n",
    "    ls_lem = []\n",
    "    for j in tokenizer.tokenize(no_retract['text'][i]):\n",
    "        try:\n",
    "            int(j)\n",
    "        except:\n",
    "            if len(j) < 45:\n",
    "                ls_words.append(j)\n",
    "                ls_lem.append(lemmatizer.lemmatize(j))\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "    clean_text.append(' '.join(ls_words))\n",
    "    clean_text_lem.append(' '.join(ls_lem))\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "print(len(no_retract['text'][1]))\n",
    "print(len(clean_text[1]))\n",
    "print(len(clean_text_lem[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retract['clean_text'] = clean_text\n",
    "no_retract['clean_text_lem'] = clean_text_lem\n",
    "no_retract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text of each article as it was originally received from the query needed to be cleaned in several ways. There were several symbols and numerical values that needed to be removed. To remove these characters, the RegexpTokenizer was used. Additionally, several \"words\" were in fact URLs or strings of characters that were not intelligible (as they may have been artifacts from mathematical equations in the article). Thus, any string that was above 45 characters was ignored. Once these cleaning steps had been taken, the text was saved in two different ways: one method with no further formatting, and one method where a lemmatizer was used. The now two different text bodies were then combined back together using spaces and added to new columns in the dataframe. Text that had no further formatting was saved as \"clean_text\" while lemmatized text was saved as \"clean_text_lem\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "            ...\n",
       "            157, 158, 159, 160, 161, 162, 163, 164, 165, 166],\n",
       "           dtype='int64', length=124)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_retract.loc[no_retract['year']==2014].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019    1891\n",
       "2016    1833\n",
       "2015    1792\n",
       "2018    1788\n",
       "2017    1786\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_retract = no_retract.drop(range(43, 167))\n",
    "no_retract['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the querying process, the dates randomly chosen were used as the end point of the query. Thus, 167 articles were pulled where each date is the last possible date the article could have been published on. Because of this, there were 124 articles that were published in 2014. For consistency, these articles were dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Combined Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([retract, no_retract], axis=0)\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retraction and no retraction dataframes were concatenated together to create a dataframe that has all of the inforamtion from all of the queries completed in the \"Data Collection\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = total.drop(columns=['id', 'language', 'publisher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = total.drop(columns=['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['year'] = total['year'].astype(str)\n",
    "total['month'] = total['month'].astype(str)\n",
    "total['day'] = total['day'].astype(str)\n",
    "total['volume'] = total['volume'].astype(str)\n",
    "total['issue'] = total['issue'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnecessary columns were dropped. The \"year,\" \"month,\" \"day,\" \"volume,\" and \"issue\" columns were retyped as strings so that they could be dummied in later notebooks. Once cleaned, the dataframe was saved into a new CSV file for proofing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv('./total_plos_only_data.csv')\n",
    "total = pd.read_csv('./total_plos_only_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.1074/jbc.M111.329078           4\n",
       "10.1371/journal.pone.0194078      2\n",
       "10.1038/cr.2011.194               2\n",
       "10.1074/jbc.M111.275073           2\n",
       "10.1371/journal.pone.0164378      2\n",
       "10.1038/cdd.2010.114              2\n",
       "10.1371/journal.pone.0212021      2\n",
       "10.1074/jbc.M110.175802           2\n",
       "10.3390/nano4020203               2\n",
       "10.1074/jbc.M808084200            2\n",
       "10.1371/journal.pone.0216079      2\n",
       "10.1371/journal.pone.0155697      2\n",
       "10.1523/JNEUROSCI.0372-13.2013    2\n",
       "10.1371/journal.pone.0146671      2\n",
       "10.1074/jbc.M112.387738           2\n",
       "10.1200/JCO.2017.74.7824          2\n",
       "10.1155/2012/236409               2\n",
       "10.1074/jbc.M709854200            2\n",
       "10.1371/journal.pone.0140044      2\n",
       "10.1371/journal.pone.0125542      2\n",
       "10.3389/fnins.2018.00529          2\n",
       "10.1371/journal.pone.0183066      1\n",
       "10.1371/journal.pone.0225345      1\n",
       "10.1371/journal.pone.0193981      1\n",
       "10.1371/journal.pone.0166478      1\n",
       "Name: doi, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['doi'].value_counts().head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = total.drop_duplicates(subset='doi', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the querying process, some DOI values were repeated even though duplicates should have been dropped before pulling from the PMC database. These DOI values are unique strings that identify a specific article. Because of this, if a DOI is repeated, then the article text is repeated within the dataframe as well. Thus, these duplicates were dropped and saved to a new CSV file for proofing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv('./total_plos_only_data_no_duplicates.csv')\n",
    "total = pd.read_csv('./total_plos_only_data_no_duplicates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950    For the chemotherapeutic activity of pyrimidin...\n",
       "951    Urinary tract infection UTI is a bacterial inf...\n",
       "952    The Bible descrbies the case of a woman with h...\n",
       "953                                                  NaN\n",
       "954    Human betaherpesviruses 6A and 6B HHV 6A and H...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['clean_text'][950:955]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the tokenizing process, one text must have been removed completely (as the text may not have had any spaces). This row was dropped as it serves no purpose to modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv('./total_data_plos_only_cleaned.csv')\n",
    "total[1537:].to_csv('./no_retraction_data_plos_only_cleaned.csv')\n",
    "total[:1537].to_csv('./retraction_data_plos_only_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the way the dataframes were concatenated, the dataframe from index 0-1537 are only retracted articles while the index 1537-10643 are only non-retracted articles. Thus, the final dataframe was saved in three different ways: the complete dataframe, only retracted articles, and only non-retracted articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
