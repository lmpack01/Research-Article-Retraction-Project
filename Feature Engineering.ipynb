{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textstat\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>doi</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>journal</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords</th>\n",
       "      <th>retraction_binary</th>\n",
       "      <th>unpacked_keywords</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1208/s12249-016-0596-x</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AAPS PharmSciTech</td>\n",
       "      <td>Study of the Transformations of Micro/Nano-cry...</td>\n",
       "      <td>‘Polymorphism’ generally referred as the abili...</td>\n",
       "      <td>This study elucidates the physical properties ...</td>\n",
       "      <td>['monoclinic', 'nano-sized crystals', 'orthorh...</td>\n",
       "      <td>1</td>\n",
       "      <td>['monoclinic', 'nano-sized', 'crystals', 'orth...</td>\n",
       "      <td>Polymorphism generally referred as the ability...</td>\n",
       "      <td>Polymorphism generally referred a the ability ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1021/acscentsci.9b00224</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ACS central science</td>\n",
       "      <td>Targeted Protein Internalization and Degradati...</td>\n",
       "      <td>Traditional\\ndrug development efforts are focu...</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Traditional drug development efforts are focus...</td>\n",
       "      <td>Traditional drug development effort are focuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10.1021/acsomega.8b00488</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ACS omega</td>\n",
       "      <td>Regulating the Microstructure of Intumescent F...</td>\n",
       "      <td>Intumescent flame retardants\\nare now being us...</td>\n",
       "      <td>A compatibilizer</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Intumescent flame retardants are now being use...</td>\n",
       "      <td>Intumescent flame retardant are now being used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10.1021/acsomega.8b00153</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ACS omega</td>\n",
       "      <td>Solid-to-Solid Crystallization of Organic Thin...</td>\n",
       "      <td>Crystal growth process is basic and essential ...</td>\n",
       "      <td>The solid-to-solid crystallization processes o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Crystal growth process is basic and essential ...</td>\n",
       "      <td>Crystal growth process is basic and essential ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10.1107/S1600536811022574</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Acta crystallographica. Section E, Structure r...</td>\n",
       "      <td>Oxonium picrate.</td>\n",
       "      <td>For general background to organic salts of pic...</td>\n",
       "      <td>The title compound, H3O+·C6H2N3O7</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>For general background to organic salts of pic...</td>\n",
       "      <td>For general background to organic salt of picr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1                         doi  \\\n",
       "0           0             0               0   10.1208/s12249-016-0596-x   \n",
       "1           1             1               1  10.1021/acscentsci.9b00224   \n",
       "2           2             2               2    10.1021/acsomega.8b00488   \n",
       "3           3             3               3    10.1021/acsomega.8b00153   \n",
       "4           4             4               4   10.1107/S1600536811022574   \n",
       "\n",
       "     year  month   day  volume  issue  \\\n",
       "0  2016.0    8.0  10.0    18.0    5.0   \n",
       "1  2019.0    5.0   9.0     5.0    6.0   \n",
       "2  2018.0    6.0  27.0     3.0    6.0   \n",
       "3  2018.0    6.0  25.0     3.0    6.0   \n",
       "4  2011.0    6.0  18.0    67.0    NaN   \n",
       "\n",
       "                                             journal  \\\n",
       "0                                  AAPS PharmSciTech   \n",
       "1                                ACS central science   \n",
       "2                                          ACS omega   \n",
       "3                                          ACS omega   \n",
       "4  Acta crystallographica. Section E, Structure r...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Study of the Transformations of Micro/Nano-cry...   \n",
       "1  Targeted Protein Internalization and Degradati...   \n",
       "2  Regulating the Microstructure of Intumescent F...   \n",
       "3  Solid-to-Solid Crystallization of Organic Thin...   \n",
       "4                                   Oxonium picrate.   \n",
       "\n",
       "                                                text  \\\n",
       "0  ‘Polymorphism’ generally referred as the abili...   \n",
       "1  Traditional\\ndrug development efforts are focu...   \n",
       "2  Intumescent flame retardants\\nare now being us...   \n",
       "3  Crystal growth process is basic and essential ...   \n",
       "4  For general background to organic salts of pic...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  This study elucidates the physical properties ...   \n",
       "1                                           Targeted   \n",
       "2                                   A compatibilizer   \n",
       "3  The solid-to-solid crystallization processes o...   \n",
       "4                  The title compound, H3O+·C6H2N3O7   \n",
       "\n",
       "                                            keywords  retraction_binary  \\\n",
       "0  ['monoclinic', 'nano-sized crystals', 'orthorh...                  1   \n",
       "1                                                 []                  1   \n",
       "2                                                 []                  1   \n",
       "3                                                 []                  1   \n",
       "4                                                 []                  1   \n",
       "\n",
       "                                   unpacked_keywords  \\\n",
       "0  ['monoclinic', 'nano-sized', 'crystals', 'orth...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  Polymorphism generally referred as the ability...   \n",
       "1  Traditional drug development efforts are focus...   \n",
       "2  Intumescent flame retardants are now being use...   \n",
       "3  Crystal growth process is basic and essential ...   \n",
       "4  For general background to organic salts of pic...   \n",
       "\n",
       "                                      clean_text_lem  \n",
       "0  Polymorphism generally referred a the ability ...  \n",
       "1  Traditional drug development effort are focuse...  \n",
       "2  Intumescent flame retardant are now being used...  \n",
       "3  Crystal growth process is basic and essential ...  \n",
       "4  For general background to organic salt of picr...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = pd.read_csv('./total_data_plos_only_cleaned.csv')\n",
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = total.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retract = pd.read_csv('./no_retraction_data_plos_only_cleaned.csv')\n",
    "no_retract = no_retract.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retract = pd.read_csv('./retraction_data_plos_only_cleaned.csv')\n",
    "retract = retract.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['year'] = total['year'].astype(str)\n",
    "total['month'] = total['month'].astype(str)\n",
    "total['day'] = total['day'].astype(str)\n",
    "total['volume'] = total['volume'].astype(str)\n",
    "total['issue'] = total['issue'].astype(str)\n",
    "\n",
    "retract['year'] = retract['year'].astype(float)\n",
    "retract['month'] = retract['month'].astype(float)\n",
    "retract['day'] = retract['day'].astype(float)\n",
    "retract['volume'] = retract['volume'].astype(float)\n",
    "retract['issue'] = retract['issue'].astype(float)\n",
    "\n",
    "no_retract['year'] = no_retract['year'].astype(float)\n",
    "no_retract['month'] = no_retract['month'].astype(float)\n",
    "no_retract['day'] = no_retract['day'].astype(float)\n",
    "no_retract['volume'] = no_retract['volume'].astype(float)\n",
    "no_retract['issue'] = no_retract['issue'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/40950791/remove-quotes-from-string-in-python\n",
    "keywords_list = []\n",
    "count = 0\n",
    "for i in retract['keywords']:\n",
    "    if i == []:\n",
    "        pass\n",
    "    else:\n",
    "        for j in i.split():\n",
    "            keywords_list.append(j.replace(\"'\",'').replace('[','').replace(',','').replace(']','').replace('(','').replace(')','').replace('\\\\n', '').replace('\\\\n','').lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            663\n",
       "cell        186\n",
       "antibody    116\n",
       "cancer      112\n",
       "response     89\n",
       "disease      84\n",
       "health       79\n",
       "factor       71\n",
       "theory       67\n",
       "gene         66\n",
       "heat         61\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cells -> cell\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ls_keywords = []\n",
    "for i in keywords_list:\n",
    "    ls_keywords.append(lemmatizer.lemmatize(i))\n",
    "pd.Series(ls_keywords).value_counts().head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keywords Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10619\n"
     ]
    }
   ],
   "source": [
    "keywords_binary = []\n",
    "for i in total['keywords']:\n",
    "    if len(i) != 2:\n",
    "        keywords_binary.append(1)\n",
    "    else:\n",
    "        keywords_binary.append(0)\n",
    "print(len(keywords_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['keywords_binary'] = keywords_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537\n"
     ]
    }
   ],
   "source": [
    "keywords_binary = []\n",
    "for i in retract['keywords']:\n",
    "    if len(i) != 2:\n",
    "        keywords_binary.append(1)\n",
    "    else:\n",
    "        keywords_binary.append(0)\n",
    "print(len(keywords_binary))\n",
    "\n",
    "retract['keywords_binary'] = keywords_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words = []\n",
    "for i in range(0, len(total['clean_text'])):\n",
    "    list_words.append(len(total['clean_text'][i].split()))\n",
    "total['num_words'] = list_words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words = []\n",
    "for i in range(0, len(total['clean_text'])):\n",
    "    list_words.append(len(total['clean_text'][i]))\n",
    "total['character_length'] = list_words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_terms = ['IACUC', 'mouse', 'mice', 'rats', 'rat', 'hamster', 'hamsters', 'pigs', 'rabbits', 'rabbit', \n",
    "                'cat', 'cats', 'dog', 'dogs', 'ungulate', 'ungulates', 'pig', 'horse', 'donkey', 'goat',\n",
    "               'bovine', 'porcine', 'murine', 'chicken', 'sheep', 'cow', 'cows', 'horses', 'goats']\n",
    "\n",
    "#http://vetmed.tamu.edu/media/2005639/vadnais%20protein%20therapeutics%202017.pdf\n",
    "#https://www.ncbi.nlm.nih.gov/books/NBK218261/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animal_binary(dataframe):\n",
    "    list_articles = []\n",
    "    iacuc = []\n",
    "    for i in range(0, len(dataframe['clean_text'])):\n",
    "        count = 0\n",
    "        for j in dataframe['clean_text'][i].split():\n",
    "            for k in animal_terms:\n",
    "                if j == k:\n",
    "                    if i not in list_articles:\n",
    "                        list_articles.append(i)\n",
    "                        iacuc.append(1)\n",
    "                        count = 1\n",
    "                else:\n",
    "                    pass\n",
    "        if count == 0:\n",
    "            iacuc.append(0)\n",
    "        else:\n",
    "            pass\n",
    "                   \n",
    "    print(len(list_articles))\n",
    "    print(len(iacuc))\n",
    "\n",
    "    dataframe['animal_binary'] = iacuc\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4289\n",
      "10619\n",
      "791\n",
      "1537\n",
      "3498\n",
      "9082\n"
     ]
    }
   ],
   "source": [
    "animal_binary(total)\n",
    "animal_binary(retract)\n",
    "animal_binary(no_retract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_animal_words(dataframe):\n",
    "    list_articles = []\n",
    "    list_words = []\n",
    "    for i in range(0, len(dataframe['clean_text'])):\n",
    "        count = 0\n",
    "        iacuc = []\n",
    "        for j in dataframe['clean_text'][i].split():\n",
    "            for k in animal_terms:\n",
    "                if j == k:\n",
    "                    if i not in list_articles:\n",
    "                        list_articles.append(i)\n",
    "                    if j not in iacuc:\n",
    "                        iacuc.append(k)\n",
    "                    count = 1\n",
    "                else:\n",
    "                    pass\n",
    "        if count == 0:\n",
    "            list_words.append([])\n",
    "        else:\n",
    "            list_words.append(iacuc)\n",
    "                    \n",
    "    print(len(list_articles))\n",
    "    print(len(list_words))\n",
    "    dataframe['animal_words'] = list_words\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4289\n",
      "10619\n",
      "791\n",
      "1537\n",
      "3498\n",
      "9082\n"
     ]
    }
   ],
   "source": [
    "list_of_animal_words(total)\n",
    "list_of_animal_words(retract)\n",
    "list_of_animal_words(no_retract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animal_dummy(word_list, column_name, dataframe):\n",
    "    column_list = []\n",
    "    for i in dataframe['animal_words']:\n",
    "        count = 0\n",
    "        for j in i:\n",
    "            for k in word_list:\n",
    "                if j == k:\n",
    "                    count = 1\n",
    "        column_list.append(count)\n",
    "    \n",
    "    dataframe[column_name] = column_list\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "iacuc = ['IACUC']\n",
    "mouse = ['mouse', 'mice']\n",
    "rat = ['rat', 'rats']\n",
    "murine = ['murine']\n",
    "hamster = ['hamster', 'hamsters']\n",
    "rabbit = ['rabbit', 'rabbits']\n",
    "cat = ['cat', 'cats']\n",
    "pig = ['pig', 'pigs', 'porcine']\n",
    "dog = ['dog', 'dogs']\n",
    "ungulate = ['ungulate', 'ungulates']\n",
    "horse = ['horse', 'horses']\n",
    "donkey = ['donkey']\n",
    "goat = ['goat', 'goats']\n",
    "cow = ['cow', 'cows', 'bovine']\n",
    "chicken = ['chicken']\n",
    "sheep = ['sheep']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_dummy(iacuc, 'iacuc', retract)\n",
    "animal_dummy(mouse, 'mouse', retract)\n",
    "animal_dummy(rat, 'rat', retract)\n",
    "animal_dummy(murine, 'murine', retract)\n",
    "animal_dummy(hamster, 'hamster', retract)\n",
    "animal_dummy(rabbit, 'rabbit', retract)\n",
    "animal_dummy(cat, 'cat', retract)\n",
    "animal_dummy(pig, 'pig', retract)\n",
    "animal_dummy(dog, 'dog', retract)\n",
    "animal_dummy(ungulate, 'ungulate', retract)\n",
    "animal_dummy(horse, 'horse', retract)\n",
    "animal_dummy(donkey, 'donkey', retract)\n",
    "animal_dummy(goat, 'goat', retract)\n",
    "animal_dummy(cow, 'cow', retract)\n",
    "animal_dummy(chicken, 'chicken', retract)\n",
    "animal_dummy(sheep, 'sheep', retract)\n",
    "\n",
    "animal_dummy(iacuc, 'iacuc', no_retract)\n",
    "animal_dummy(mouse, 'mouse', no_retract)\n",
    "animal_dummy(rat, 'rat', no_retract)\n",
    "animal_dummy(murine, 'murine', no_retract)\n",
    "animal_dummy(hamster, 'hamster', no_retract)\n",
    "animal_dummy(rabbit, 'rabbit', no_retract)\n",
    "animal_dummy(cat, 'cat', no_retract)\n",
    "animal_dummy(pig, 'pig', no_retract)\n",
    "animal_dummy(dog, 'dog', no_retract)\n",
    "animal_dummy(ungulate, 'ungulate', no_retract)\n",
    "animal_dummy(horse, 'horse', no_retract)\n",
    "animal_dummy(donkey, 'donkey', no_retract)\n",
    "animal_dummy(goat, 'goat', no_retract)\n",
    "animal_dummy(cow, 'cow', no_retract)\n",
    "animal_dummy(chicken, 'chicken', no_retract)\n",
    "animal_dummy(sheep, 'sheep', no_retract)\n",
    "\n",
    "animal_dummy(iacuc, 'iacuc', total)\n",
    "animal_dummy(mouse, 'mouse', total)\n",
    "animal_dummy(rat, 'rat', total)\n",
    "animal_dummy(murine, 'murine', total)\n",
    "animal_dummy(hamster, 'hamster', total)\n",
    "animal_dummy(rabbit, 'rabbit', total)\n",
    "animal_dummy(cat, 'cat', total)\n",
    "animal_dummy(pig, 'pig', total)\n",
    "animal_dummy(dog, 'dog', total)\n",
    "animal_dummy(ungulate, 'ungulate', total)\n",
    "animal_dummy(horse, 'horse', total)\n",
    "animal_dummy(donkey, 'donkey', total)\n",
    "animal_dummy(goat, 'goat', total)\n",
    "animal_dummy(cow, 'cow', total)\n",
    "animal_dummy(chicken, 'chicken', total)\n",
    "animal_dummy(sheep, 'sheep', total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.514639\n",
       "0    0.485361\n",
       "Name: animal_binary, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['animal_binary'][:1537].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.614843\n",
       "1    0.385157\n",
       "Name: animal_binary, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['animal_binary'][1537:].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3214\n",
      "10619\n"
     ]
    }
   ],
   "source": [
    "list_articles = []\n",
    "irb = []\n",
    "for i in range(0, len(total['clean_text'])):\n",
    "    count = 0\n",
    "    word_count = 0\n",
    "    patient_count = 0\n",
    "    for j in total['clean_text'][i].split():\n",
    "        if j == 'IRB' or j == 'case' or j == 'participants':\n",
    "            if j =='IRB' or j == 'participants':\n",
    "                if i not in list_articles:\n",
    "                    list_articles.append(i)\n",
    "                    irb.append(1)\n",
    "                    count = 1\n",
    "            else:\n",
    "                try:\n",
    "                    if total['clean_text'][i].split()[word_count+1] == 'study':\n",
    "                        if i not in list_articles:\n",
    "                            list_articles.append(i)\n",
    "                            irb.append(1)\n",
    "                            count = 1\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    pass            \n",
    "        else:\n",
    "            pass\n",
    "        word_count += 1\n",
    "    if count == 0:\n",
    "        irb.append(0)\n",
    "    else:\n",
    "        pass\n",
    "                  \n",
    "print(len(list_articles))\n",
    "print(len(irb))\n",
    "total['irb_binary'] = irb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.829538\n",
       "1    0.170462\n",
       "Name: irb_binary, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['irb_binary'][:1537].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.674961\n",
       "1    0.325039\n",
       "Name: irb_binary, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['irb_binary'][1537:].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regulatory Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10619"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regulatory = []\n",
    "for i in range(0, len(total['irb_binary'])):\n",
    "    if total['irb_binary'][i] == 1 or total['animal_binary'][i] == 1:\n",
    "        if total['irb_binary'][i] == 1 and total['animal_binary'][i] == 1:\n",
    "            regulatory.append(2)\n",
    "        else:\n",
    "            regulatory.append(1)\n",
    "    else:\n",
    "        regulatory.append(0)\n",
    "len(regulatory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.545869\n",
       "0    0.384515\n",
       "2    0.069616\n",
       "Name: regulatory, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['reg_binary'] = regulatory\n",
    "total = total.rename(columns={'reg_binary':'regulatory'})\n",
    "total['regulatory'][:1537].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.581150\n",
       "0    0.354327\n",
       "2    0.064523\n",
       "Name: regulatory, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['regulatory'][1537:].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n",
      "10619\n"
     ]
    }
   ],
   "source": [
    "list_articles = []\n",
    "review = []\n",
    "for i in range(0, len(total['clean_text'])):\n",
    "    count = 0\n",
    "    word_count = 0\n",
    "    for j in total['clean_text'][i].split():\n",
    "        if j == 'review':\n",
    "            if total['clean_text'][i].split()[word_count-1] == 'this':\n",
    "                if i not in list_articles:\n",
    "                    list_articles.append(i)\n",
    "                    review.append(1)\n",
    "                    count = 1\n",
    "        else:\n",
    "            pass\n",
    "        word_count += 1\n",
    "    if count == 0:\n",
    "        review.append(0)\n",
    "    else:\n",
    "        pass\n",
    "                  \n",
    "print(len(list_articles))\n",
    "print(len(review))\n",
    "\n",
    "total['review_binary'] = review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.960963\n",
       "1    0.039037\n",
       "Name: review_binary, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['review_binary'][:1537].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.980841\n",
       "1    0.019159\n",
       "Name: review_binary, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['review_binary'][1537:].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novel Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1565\n",
      "10619\n"
     ]
    }
   ],
   "source": [
    "list_articles = []\n",
    "novel_idea = []\n",
    "for i in range(0, len(total['clean_text'])):\n",
    "    count = 0\n",
    "    novel_count = 0\n",
    "    for j in total['clean_text'][i].split():\n",
    "        if j == 'novel':\n",
    "            for k in total['clean_text'][i].split():\n",
    "                if k == 'novel':\n",
    "                    novel_count += 1\n",
    "            if novel_count > 1:\n",
    "                if i not in list_articles:\n",
    "                    list_articles.append(i)\n",
    "                    novel_idea.append(1)\n",
    "                    count = 1\n",
    "        else:\n",
    "            pass\n",
    "    if count == 0:\n",
    "        novel_idea.append(0)\n",
    "    else:\n",
    "        pass\n",
    "            \n",
    "print(len(list_articles))\n",
    "print(len(novel_idea))\n",
    "total['novel_idea'] = novel_idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.826936\n",
       "1    0.173064\n",
       "Name: novel_idea, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['novel_idea'][:1537].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.85697\n",
       "1    0.14303\n",
       "Name: novel_idea, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['novel_idea'][1537:].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readability(dataframe):\n",
    "    flesch_reading_ease_value = []\n",
    "    flesch_kincaid_grade_value = []\n",
    "    \n",
    "    for i in dataframe['clean_text']:\n",
    "        flesch_reading_ease_value.append(textstat.flesch_reading_ease(i))\n",
    "        flesch_kincaid_grade_value.append(textstat.flesch_kincaid_grade(i))\n",
    "\n",
    "    dataframe['flesch_reading_ease'] = flesch_reading_ease_value\n",
    "    dataframe['flesch_kincaid_grade'] = flesch_kincaid_grade_value\n",
    "    print(len(dataframe['flesch_reading_ease']))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537\n",
      "9082\n",
      "10619\n"
     ]
    }
   ],
   "source": [
    "readability(retract)\n",
    "readability(no_retract)\n",
    "readability(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "retract.to_csv('./retract_feature_engineered_data.csv')\n",
    "no_retract.to_csv('./no_retract_feature_engineered_data.csv')\n",
    "total.to_csv('./total_feature_engineered_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
